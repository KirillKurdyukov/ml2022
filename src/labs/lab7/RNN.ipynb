{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01cb5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "text = open('./data/LSTM_HABR.txt', 'r', encoding='utf-8').read().lower()\n",
    "text = re.sub(r'[^а-я\\s\\d.!\\?-]+', '', text)\n",
    "text = re.sub(r'\\s+', ' ', text) \n",
    "text = re.sub(r'[!\\?]+', '.', text)\n",
    "sentences = text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1ba0de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_strings(x, y, window):\n",
    "    for sentence in sentences:\n",
    "        sentence += '.'\n",
    "        for i in range(0, len(sentence) - window):\n",
    "            x.append(sentence[i:i + window])\n",
    "            y.append(sentence[i + window])\n",
    "    return len(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66653491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 42)\n"
     ]
    }
   ],
   "source": [
    "chars = set(text)\n",
    "size_vocab = len(chars)\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "window = 25\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "    \n",
    "size_sentences = fill_strings(X, Y, window)\n",
    "x_train = np.zeros((size_sentences, window, size_vocab), dtype=np.bool_)\n",
    "y_train = np.zeros((size_sentences, size_vocab), dtype=np.bool_)\n",
    "\n",
    "for i in range(0, size_sentences):\n",
    "    x_cur = X[i]\n",
    "    y_cur = Y[i]\n",
    "    for j, ch in enumerate(x_cur):\n",
    "        x_train[i, j, char_to_int[ch]] = True\n",
    "    y_train[i, char_to_int[y_cur]] = True \n",
    "    \n",
    "print(x_train.shape[1:])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a501fcb",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8608e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "444/444 [==============================] - 26s 54ms/step - loss: 3.1900\n",
      "Epoch 2/40\n",
      "444/444 [==============================] - 24s 54ms/step - loss: 2.9525\n",
      "Epoch 3/40\n",
      "444/444 [==============================] - 27s 62ms/step - loss: 2.6953\n",
      "Epoch 4/40\n",
      "444/444 [==============================] - 30s 68ms/step - loss: 2.5581\n",
      "Epoch 5/40\n",
      "444/444 [==============================] - 35s 78ms/step - loss: 2.4442\n",
      "Epoch 6/40\n",
      "444/444 [==============================] - 31s 70ms/step - loss: 2.3582\n",
      "Epoch 7/40\n",
      "444/444 [==============================] - 29s 65ms/step - loss: 2.2765\n",
      "Epoch 8/40\n",
      "444/444 [==============================] - 32s 72ms/step - loss: 2.2008\n",
      "Epoch 9/40\n",
      "444/444 [==============================] - 29s 65ms/step - loss: 2.1295\n",
      "Epoch 10/40\n",
      "444/444 [==============================] - 28s 64ms/step - loss: 2.0666\n",
      "Epoch 11/40\n",
      "444/444 [==============================] - 37s 84ms/step - loss: 2.0110\n",
      "Epoch 12/40\n",
      "444/444 [==============================] - 28s 62ms/step - loss: 1.9666\n",
      "Epoch 13/40\n",
      "444/444 [==============================] - 24s 54ms/step - loss: 1.9200\n",
      "Epoch 14/40\n",
      "444/444 [==============================] - 28s 63ms/step - loss: 1.8629\n",
      "Epoch 15/40\n",
      "444/444 [==============================] - 28s 63ms/step - loss: 1.8252\n",
      "Epoch 16/40\n",
      "444/444 [==============================] - 29s 64ms/step - loss: 1.7728\n",
      "Epoch 17/40\n",
      "444/444 [==============================] - 36s 81ms/step - loss: 1.7354\n",
      "Epoch 18/40\n",
      "444/444 [==============================] - 30s 67ms/step - loss: 1.6999\n",
      "Epoch 19/40\n",
      "444/444 [==============================] - 35s 78ms/step - loss: 1.6603\n",
      "Epoch 20/40\n",
      "444/444 [==============================] - 34s 77ms/step - loss: 1.6306\n",
      "Epoch 21/40\n",
      "444/444 [==============================] - 30s 68ms/step - loss: 1.5813\n",
      "Epoch 22/40\n",
      "444/444 [==============================] - 35s 78ms/step - loss: 1.5528\n",
      "Epoch 23/40\n",
      "444/444 [==============================] - 34s 77ms/step - loss: 1.5115\n",
      "Epoch 24/40\n",
      "444/444 [==============================] - 31s 70ms/step - loss: 1.4732\n",
      "Epoch 25/40\n",
      "444/444 [==============================] - 31s 69ms/step - loss: 1.4607\n",
      "Epoch 26/40\n",
      "444/444 [==============================] - 30s 67ms/step - loss: 1.4164\n",
      "Epoch 27/40\n",
      "444/444 [==============================] - 25s 56ms/step - loss: 1.3911\n",
      "Epoch 28/40\n",
      "444/444 [==============================] - 31s 69ms/step - loss: 1.3518\n",
      "Epoch 29/40\n",
      "444/444 [==============================] - 25s 57ms/step - loss: 1.3307\n",
      "Epoch 30/40\n",
      "444/444 [==============================] - 25s 57ms/step - loss: 1.2911\n",
      "Epoch 31/40\n",
      "444/444 [==============================] - 28s 62ms/step - loss: 1.2680\n",
      "Epoch 32/40\n",
      "444/444 [==============================] - 30s 67ms/step - loss: 1.2597\n",
      "Epoch 33/40\n",
      "444/444 [==============================] - 27s 62ms/step - loss: 1.2254\n",
      "Epoch 34/40\n",
      "444/444 [==============================] - 25s 57ms/step - loss: 1.1992\n",
      "Epoch 35/40\n",
      "444/444 [==============================] - 28s 64ms/step - loss: 1.1655\n",
      "Epoch 36/40\n",
      "444/444 [==============================] - 30s 68ms/step - loss: 1.1542\n",
      "Epoch 37/40\n",
      "444/444 [==============================] - 25s 56ms/step - loss: 1.1131\n",
      "Epoch 38/40\n",
      "444/444 [==============================] - 29s 66ms/step - loss: 1.0961\n",
      "Epoch 39/40\n",
      "444/444 [==============================] - 40s 91ms/step - loss: 1.0549\n",
      "Epoch 40/40\n",
      "444/444 [==============================] - 30s 68ms/step - loss: 1.0393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1285e7370>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "np.random.seed(42)\n",
    " \n",
    "model = Sequential(\n",
    "    [\n",
    "        LSTM(100, input_shape=x_train.shape[1:], dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n",
    "        LSTM(100),\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam')\n",
    "model.fit(x_train, y_train, batch_size=20, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cd6a06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sentence: \"овые значения-кандидаты у\"\n",
      "станующих слово состояние ячейки объединяет в работе 2015 года провлемы долговременных зависимостей "
     ]
    }
   ],
   "source": [
    "index = np.random.randint(0, len(x_train) - 1)\n",
    "sentence = X[index]\n",
    "print('Start sentence: \"' + sentence + '\"')\n",
    "for i in range(100):\n",
    "    x_pred = np.zeros((1, window, size_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_to_int[char]] = 1.0\n",
    "    preds = model.predict(x_pred)                    \n",
    "    next_char = int_to_char[np.argmax(preds)]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    print(next_char, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012e624",
   "metadata": {},
   "source": [
    "# Markov chane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b03a9327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sentence: \"ный сл\"\n",
      "ой нейронные сети содержат обратные связи позволяющие сохранить а 0 полностью они были представлены "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "window = 6\n",
    "markov_X = []\n",
    "markov_Y = []\n",
    "fill_strings(markov_X, markov_Y, window)\n",
    "\n",
    "nodes = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sentence, symbol in zip(markov_X, markov_Y):\n",
    "    nodes[sentence][symbol] += 1\n",
    "\n",
    "index = np.random.randint(0, len(markov_X) - 1)\n",
    "\n",
    "sentence = markov_X[index]\n",
    "print('Start sentence: \"' + sentence + '\"')\n",
    "for i in range(100):\n",
    "    next_chars_pool = [symbol for symbol in nodes[sentence]]\n",
    "    probas = np.array([w for w in nodes[sentence].values()])\n",
    "    probas = probas / probas.sum()\n",
    "    if len(probas) == 0:\n",
    "        break\n",
    "    next_char = next_chars_pool[np.argmax(probas)]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    print(next_char, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e1551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
